# -*- coding: utf-8 -*-
"""Project 1 : Gold Price Prediction using Random Forest Regressor and Neural Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yFOMJtZMNQudQvzI6kwp7WjALb8y6obD

importing libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics

"""data collection and processing

"""

#loading csv data to pandas data frame
gold_data = pd.read_csv('/content/gld_price_data.csv') # pd.read reads file

# print 5 entries from data set
gold_data.head()

# print last 5 rows of data frams
gold_data.tail() # opposite of head show last 5 entries

# numer of rows and column
gold_data.shape # print rows, column

#getting some basic info about data
gold_data.info()

# checking number of missing nulls
gold_data.isnull().sum() # will give us number of missing nulls in each column

# getting some statistical measures of data
gold_data.describe()# it will give us like mean, std, count percentage values

"""correlation :
1. positive correlation
2. negative correlation

"""

correlation = gold_data.select_dtypes(include=[np.number]).corr()
# this function selects the columns that datatype of number and shows it

# construting heap map to understand correlation
plt.figure(figsize = (8,8))
sns.heatmap(correlation, cbar = True, square = True, fmt = '.1f', annot = True, annot_kws={'size': 8}, cmap = 'Blues')
# cbar = color bar , square = to give square format,
# fmt = number of decimal points, annot = name of the columns as annotations
# annot_kws = size of annotations, cmap = also for color blue to plot
# here we can see gold is positive correlated with silver both increasing with
# value 0.9

# correlation values of GLD
print(correlation['GLD']) # how elements are correlated like silver +ive correlated

# checking the distribution of the GLD prices , basically range of it
sns.distplot(gold_data['GLD'], color = 'green') # gives density with price increase
# so most values lie in 120 range

# checking the distribution of the GLD prices , basically range of it
sns.histplot(gold_data['GLD'], color = 'green') # gives density with price increase
# so most values lie in 120

"""spliting the features and targeting the gold data"""

# split the features like uso, slv an target on gold data
X = gold_data.drop(['Date', 'GLD'], axis=1) # in gold data we are gonna drop date and
# gold column and axis = 1 is for column and for row axis = 0
Y = gold_data['GLD']
print(X)

print(Y)

"""Splitting into Training Data and Test Data"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)
# gonna spilt X into train and test with ratio
# 80% in X_train and 20% X_test similar condition for y (gold prices) also
# this function splits X and Y general test size is 20 percentage= 0.2 and
# and random state is when we split data the random state should be equal to
# value given in size to reproduce the code in same way
# we are splitting data in xtrain and ytest and we have corresponding
# ytrain to x train and ytest to xtest

"""Model Training: Random Forest Regressor"""

regressor = RandomForestRegressor(n_estimators=100) # loaded regressor model to
# this regressor variable

# training the model
regressor.fit(X_train, Y_train) # fit function will fir our data to regression
# model

"""Model Evaluation"""

# prediction on Test Data
test_data_prediction = regressor.predict(X_test) # predict funtion will predict
# gold values it will give values of X_test

print(test_data_prediction)

# now to compare this predicted values with actual values
# so here we will use R squared error and we can use matrix
error_score = metrics.r2_score(Y_test, test_data_prediction)
# we mentioned real value = Y_test and predicted in testdataprediction
print("R squared error : ", error_score)

"""Compare the actual values and Predicted values in a Plot"""

Y_test = list(Y_test)

plt.plot(Y_test, color = 'blue', label = 'Actual Value')# this are actual values
# that are labelled and with color blue
plt.plot(test_data_prediction, color = 'green', label = 'Predicted values')
plt.title("Actual price vs Predicted price") # gives title to graph
plt.xlabel("Number of values") # gives xaxis name
plt.ylabel("Gold price") # gives y axis name
plt.legend()
plt.show()

"""Lets do gold prediction with Neural Networks and compare both the models"""

import tensorflow as tf
from tensorflow import keras # keras used for building & training neural networks

"""Building Neural Network"""

neural_network = keras.Sequential([
    keras.layers.Dense(64, activation = 'relu', input_shape = (X_train.shape[1],)),
    keras.layers.Dense(64, activation = 'relu'),
    keras.layers.Dense(1)
])

"""Compiling the model"""

neural_network.compile(optimizer = 'adam', loss = 'mean_squared_error')
# adam is a optimizer that adjusts learning rate during training for faster coverage
# 'mean-squared-error = measures average of squares of errors between actual
# and predicted values, suitable for regression problem

"""Training the model"""

import time
start_time = time.time() # is used to measure start and end times of training

neural_network.fit(X_train, Y_train, epochs = 100, batch_size = 32, verbose = 1)
# epochs  = number of times model iterates
# batch size = number of samples processed before model is updated

end_time = time.time() # this time.time() functions used 2 times helps us to
# calculate the toal training time
neural_network_training_time = end_time - start_time
print(f"Neural Network Training Time : {neural_network_training_time :.2f} seconds")

"""Evaluate the model"""

nn_test_data_prediction = neural_network.predict(X_test)
# predict function = generate predictions for test data using trained model

"""calculate R-squared error for nn model"""

nn_error_score = metrics.r2_score(Y_test, nn_test_data_prediction)
# it evaluates how well models prediction match actual data
print("Neural Network R squared error :", nn_error_score)

"""Plotting Actual vs Predicted values"""

plt.plot(Y_test, color='blue', label = 'Actual value')
plt.plot(nn_test_data_prediction, color='red', label = 'NN Predicted Value')
plt.title("Actual price vs Neural Network Predicted Price")
plt.xlabel("Number of Values")
plt.ylabel("Gold Price")
plt.legend()
plt.show()

"""Comparison between Random Forest Model and Neural Network model"""

print("\nComparison: ")
print(f"Random Forest R squared error: {error_score}")
print(f"Neural Network R squared error: {nn_error_score}")

"""By comparing the models it shows that Random Forest Regressor has more R squared error than Neural Network it means Random forest is more convenient than Neural Network in this case"""